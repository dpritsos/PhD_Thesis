%!TeX spellcheck = en-US

%\chapter{Open-set and Closed-Set Classification for WGI}
\chapter{Open-set WGI algorithms}

\label{chap:openset}

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Introduction}\label{chap:openset:sec:intro}


In this chapter three open-set algorithms are described in detailed where they have been developed for the WGI task. These algorithms is an algorithmic extension of the most popular closed-set algorithms and basic approaches one can follow. Although, their base algorithms are trivial their open-set extension are covering some sophisticated issues of the \textit{Automated Genre Identification} and specifically the WGI. 

Particularly, the \textit{One Class SVM Ensemble (OCSVME)} has been developed which is an extension of the One Class SVM (OCSVM) where the later is also an extension of the $\nu$-SVM. Note that SVM is design for closed-set classification scenario and also the $\nu$-SVM. The OCSVM is a form of binary classifier with the special case where only positive samples are available for the training phase. Also, only the center of the vector space and few of the positive examples (called outliers), are considered as negative examples. The OCSVME is an open-set and multi-class classification form of the SVM which fits the WGI task. 

The \textit{Random Feature Subpacing Ensemble} is an other algorithm developed for this thesis, for fitting the open-set scenario of the WGI task. This is a distance based algorithm where a random set of features is selected for comparing the distance of the class and an arbitrary document. Several distance measures can be used such as the \textit{Cosine, Min-Max, Euclidean, Mahalanobis, etc}. The distance based algorithms seem to work very efficiently for WGI as in several text mining problems with high dimensional space.

The \textit{Nearest Neighbors Distance Ratio (NNDR)} is the final algorithm developed in this thesis specially for WGI task. It is based on the same NNDR developed for \parencite{} which also is special case of the \textit{Nearest Neighbor (NN)} for fitting the open set scenario. 

As explained in chapter \ref{chap:relevant_work} there are several issues relate to the WGI. Every of the above algorithms has been developed for tackling the major ones in respect of the Machine Learning bound issues perspective. 

Considering the experimental set-up in the WGI there are two issues. Firstly, the Genre domain is practically infinite due to the constantly emerging new genre and their temporal manner where they are reformed through time. Secondly, due to the great scale of the Web it is impossible to collect a characteristic statistically correct negative set of examples. Although, there is a plethora of positive examples for a genre. The OCSVME has been developed in this issues in mind. Since, it can work with only positive examples and also can work in a open-set framework of experiments.

The second issue is the great dimensionality where is a general text mining issues. However, for WGI the constrains of the very small scaled corpora available for the very high scale problem considering the Web. Moreover, in section \ref{chap:relevant_work:sec:features} it is discussed that the main research focus was around the problem of the proper feature selection for the WGI. Having this in mind the RFSE is a competent algorithm for selecting the proper features implicitly based on the majority statistics. It can also work in the open-set framework.

The open-set classification itself is opening an other difficulty which is called the \textit{Open Space Risk (OSR)}. That is, the risk of placing the decision boundaries too far or close due to the presences of Outages the luck of \textit{Negative samples} and the \textit{(structured or unstructured) Noise}. The NNDR has originally developed having the regularization of the OSR in mind and in this thesis it has been specially developed of the WGI task. The formal definition for the OSR can be found in section \ref{chap:eval_mentods:sec:open_space_risk}.

Finally, all three algorithms have been developed with Noise handling and Outages tolerance in mind. Specifically, all three algorithm can be tuned to regulate their Noise filtering ability with an explicit or implicit threshold. The Noise as explained earlier can be structured or unstructured, i.e. when the noise samples are balanced or not in respect of the genre tags. Note that the noise-filtering regularization threshold is automatically defined for NNDR while training using the OSR as a measure.

In the rest of this chapter a section is dedicated for one of every algorithm starting with the OCSVM as prerequisite for explaining the open-set flowing algorithms.


\section{One-class Closed-set Classification Methods}\label{chap:openset:sec:One_Class_Classification}

The main difference of the One Class Classification problem (OCC) with respect to the conventional multi-class or binary classification problem is that in OCC there are only available positive examples of a class and none or very few negative examples. There are several approaches towards the solution of this problem. A compact survey on OCC is provided by Khan et al.\parencite{khan2010survey}. 

To begin with there are several references to the well known \parencite{scholkopf1999estimating} which actually presents an alternative solution to the problem of \textit{the overlapping samples distributions}, known as $\nu$-SVM \parencite{bishop2006}. The nature of $\nu$-SVM is allowing us to use it effortless in binary classification problems as long as to OCC problems. The parameter $\nu$ is both controlling the fraction of SVs and the \textit{margin errors}, i.e. point out the positive sample considered as outliers. 

In the case of OCSVM the optimization process begins with considering, as the only negative example, \textit{the origin} of the vector space defined from the \textit{data space}. More details for OCSVM are given into the section \ref{chap:openset:sec:OCSVM_description}.

Outlier-SVM is an OCSVM the algorithm of \parencite{manevitz2002one,khan2010survey}. In their algorithm the \textit{Hamming distance} has been used. Their model was competitive but not top performer when comparing their model to other OCSVM algorithms such as One Class Neural Networks, One Class Naive Bayes Classifier, One Class Nearest Neighbor, and Rocchio Prototype. In addition their algorithm is sensitive to the term weigting schema, i.e. \textit{Binary, TF, TF-IDF, etc.}, and vector dimensionality. 

The \textit{Rocchio's algorithm} is the simplest one class classification algorithm where it has been used for IR problems because of its simplicity and consistency \parencite{joachims1997probabilistic}. The learning process is just the summation of all the sample vector of a class, i.e the \textit{prototype vector}. An arbitrary vector is classified as positive or negative using the angular distance from the prototype vector.

Datta (cited in \parencite{manevitz2002one}) proposed Naive Bayes Classifier modification for OCC problems and use only positive samples in the learning process. A \textit{probability density function} of a class $E$ is induced as prediction model. Classifying the a document $d$ involves calculating the probability of the document $p(d|E)$ which is equal to the product of its features $w_{n}$ probabilities $p(w|E)$, where $n$ is the number of document's feature vector. To decide weather the document is classified as positive its required a threshold. 

There are, also, some OCC methods exploiting the availability of \textit{unlabeled data} as the following cases. 

\parencite{yu2005single} proposed two OCC algorithms that use positive and \textit{unlabeled data} for building a classification model that describes the \textit{single class boundary}. The \textit{Mapping Convergence}(MC) algorithm is incrementally labeling negative data from an \textit{unlabeled data set} using the margin maximization property of SVM. The \textit{Support Vector Mapping Convergence} (SVMC) optimizes the MC algorithm for fast training. Both algorithms had been compared into a real world text classification, letter recognition, and diagnosis of breast cancer with higher performance that other similar algorithms. These similar algorithms are \textit{Spy Expectation Maximization (S-EM), SVM-NN (i.e. C-SVM using unlabeled data point as negative ones) and Naive Bayes Classifier with noise sampels} \parencite{liu2002partially, li2003learning}.

To conclude, the one class classification is facilitating the problem of only positive available samples either for the one-vs-rest case \parencite{khan2010survey,manevitz2002one,yu2005single,scholkopf1999estimating,li2003learning}. In the next chapter \ref{chap:openset:sec:Openset_Class_Classification} the open-set classification problem is discussed and the three algorithm developed for this thesis are presented in detail.



\section{Open-set Classification}\label{chap:openset:sec:Openset_Class_Classification}

In this chapter three open-set algorithms developed for this thesis are discussed in detail where their evaluation experiments will be presented in chapter \ref{chap:noise}. 


The open-set classification in this thesis primarily employed to handle the \textit{structure and unstructured Noise}. However, there are several motivations for employing the open-set approach and several directions respectively to the task. In order to explain the algorithms of this thesis, the open-set frame set is described briefly in the next few paragraphs.

The open-set approach in ML has a long, yet sparse, history with the following ML method bases \parencite{geng2018recent}:

\begin{itemize}
    \item Traditional ML methods.
    \item Deep Neural Networks.
    \item Adversarial Learning.
    \item Extreme Value Theory.
    \item Dirichlet Process.
    \item "Open World Recognition".
\end{itemize}

The traditional based methods is actually the adoption of the well known closed-set algorithms to the open-set framework. Starting with the infamous SVM and the open-set form of \parencite{manevitz2002one} (mentioned in section \ref{chap:openset:sec:One_Class_Classification}) and the algorithm of \parencite{scheirer2013toward}. The later called \textit{1-vs-Set SVM} is the algorithm introduced the \textit{Open Spce Risk} term and first approach of handling the space of the unknown samples where in this chapter is called \textit{unstructured noise}. 

The \textit{1-vs-Set SVM} is the first attempt to regulate the open space that is the area between the space occupied by the incomplete negative samples and the space of the well defined positive samples. Thus, it is assumed One-class classification scenario and not multi-class. Moreover, it is reported that even thought its somehow the problem is regulated still there is some open space undefined. Probably because the implementation is only possible to work on linear space (by the other of this thesis coding experience). There are also several more efforts on the evolution of this SVM based approach found in \parencite{geng2018recent}, such as the W-SVM, POS-SVM (POS = probabilistic open set), etc.

The \textit{Distance Based} algorithms can be adopted in the open-set framework by bounding the true positive samples by the outliers. Nearest Non-Outlier (NNO) algorithms is a center based method where the OSR regularization is their method for keeping the outliers bounded. There are several center based algorithms one of them is the RFSE algorithm developed for this thesis and described in \ref{chap:openset:sec:RFSE_Description}. 

\begin{definition}{\textit{Open-set Identification}}
describes a scenario where samples of unseen, in training phase, classes appear in testing phase. Then the classifiers classify accurately the the \textit{known classes} and also effectively deal with the unknown ones. Therefore, the classifiers need to have a \textit{rejection option} when an arbitrary sample is from an unknown class \parencite{geng2018recent}.
\end{definition}
    
Although, the rejection option is emphasized in the definition of the open-set identification, the algorithms with rejection option are not open-set by default. Particularly there are several scenarios such as in \parencite{onan2018ensemble} where this option is used for rejecting the outages for improving the precision score. However, the framework remains as closed-set.
    
The open-set classification framework is closely related to the \textit{Novelty Detection} and the \textit{One-class Classification} where it is assumed that only positive examples are available for the surprised model induction methods. These methods then have been adapted to this problem and there are several examples such as One-Class SVM, One-Class Neural Networks etc.

The Nearest Neighbor algorithm which is also distance based has been adopted to the open-set framework named \textit{Nearest Neighbor Distance Ration (NNDR}). However, this algorithm it is a multi-class classification algorithm and there is no need for an adaption for this as in the above class identification cases.

The NNDR is using he distance ration in order to regulate both the outlier bound and the OSR. Details for the NNDR are described in section \ref{chap:openset:sec:NNDR_Description} and particularly a special version of it for the WGI task developed for this thesis. It should be noted that due to its decision process where two candidate samples are selected in each step this algorithm is sensitive to outlier, however, it seems that the dimensionality of the feature space can radically change its performance as shown in chapter \ref{chap:word_embeddings}.

The NNDR is also designed to regulate the OSR and this is part of its learning process where it divided the training data in to segments for regulating this problem in advanced. 

The {Open-Space Risk} is a definition form the domain of pen-Set classification research to describe the weakness of the current closed-set ML algorithms usually are used out-of-the-box to regulate low Recall performance of the models due to the luck of negative samples. In order to measure the performance of such algorithms the \textit{Openness} test have very recently introduced. 

A more formal definition of the Open-set classification is the one where the open space risk is considered.

%\theoremstyle{definition}
\begin{definition}{\textit{Open-set Multi-class Classification}}

Let $C$ be the training data, and let $R_{O}$ open space risk and $R_{ε}$ the empirical risk. Then the objective of open-set classification is to find a function $f \in L$ which is minimizing the following \textit{Open-Set Risk}. 

Mathematically described as $arg_{min} \{R_{O(f )} + \lambda R_{ε (f (V ))}\}$, where $f (x) > 0$ implies correct recognition and $\lambda$ is a regularization constant.

Thus \textit{open-set risk} balances the \textit{empirical risk} and the \textit{open space risk} over the space of allowable recognition functions \parencite{geng2018recent}.

\end{definition}

In practice the \textit{empirical risk} is the weighted loss function of the open-set multi-class classification model. The \textit{open space risk} is in practice the ratio of the open vector space to the full vector space, where the full vector space is the concatenation of the space defined by the known data samples and the unconstrained unknown space.

The \textit{Deep Neural Networks} are usually developed with a \textit{SoftMax} function forcing the whole modeling setup to induce a closed-set model. However, there have been several efforts where most of them are based on a \textit{OpenMax}. These efforts seemed fruitful and more details on this subject can be found in \parencite{geng2018recent}. Moreover, the Deep Neural Networks have also been used with great success in Language neural modeling where details can be found in chapter \ref{chap:word_embeddings}. These, models can also be used as an input on open-set algorithms an as it is shown in this thesis this approach can drastically change their performance, especially for the WGI task.

The \textit{Adversarial Learning (AL)} is a technique where \textit{generative models (i.e. sampling models)} are used for creating a set of artificial samples augmenting the real samples for training \textit{discriminative models}. This technique can be adopted for the open-set framework by modeling the positive samples. Some attempted to create adversarial models of negative samples, based on the positive ones. Generative OpenMax Model or G-OpenMax is one of the open-set adversarial models \parencite{geng2018recent}.

The \textit{Extreme Value Theory (EVT)} and \textit{Sparse Representation based} approached is an other group of ML algorithms adopted for the open-set scenario. EVT is a statistical method where the tails of the \textit{distance distributions} can be modeled using the \textit{asymptotic theory}. Thus, the distribution of the \textit{margin distance of each sample to each class} can be approximated. Then this distribution is the boundary for discarding the outlier and the rest of the unknown space (and ultimately the the open space).

In all the open-set algorithms discussed so far and implemented of this thesis, the goal is the discovery of the threshold implicitly or explicitly, as a rejection criterion in the classification process. Thus the threshold plays a key role. Introducing threshold inevitably the OSR is introduced. An other approach for tackling this problem is the \textit{Dirichlet Process} for the open-set scenario \parencite{geng2018recent}.

The \textit{Dirichlet Process} is considering a distribution over distributions and thus the induced model is not totally depended on the training samples. The Hierarchical Dirichlet Process (HDP) has been used for the open-set classification where \textit{co-clustering} is used in the training phase and \textit{Gaussian Mixture Modeling (GMM)}is used in the texting phase. The ideal is that the negative class will be also modeled, although incomplete. Thus there is no need for some threshold. The Collective Decision Open Set Recognition (CDOSR) is such an algorithm which as reported by the authors, the it is just as a conceptual proof and there are still many limitations \parencite{geng2018collective} [cited in \parencite{geng2018recent}].


\subsection{Noise defined in the open-set classification}\label{chap:openset:sec:Noise_definition}

In this thesis \textit{Noise} is the main subject in the context of open-set multi-class classification for the WGI task. The open-set framework is making things more complicated and in this paragraph are clarified and defined. 

In the open-set scenario, i.e. the real world or production conditions, we have the sow called known-known, known-unknown, unknown-known, unknown-unknown classed and the outliers  which are defined as follows \parencite{geng2018recent}:

\begin{itemize}
    \item \textit{known-known} are the positive samples also, with all the side information available, such as the connections, if any, of the sample sets.
    \item \textit{known-unknown} the negative samples with or without the side information available. Thus, partly or totally can be the rest of the positive samples in the 1-vs-rest training.
    \item \textit{unknown-known} the positive samples can be created by a sampling of a positive model, based on the known positive samples and the side information.
    \item \textit{unknown-unknown} samples with no information related to them, neither if they are positive, negative or both. Moreover, there is no side information about them and no model to be sampled can be available. 
    \item \textit{Outliers} a set of positive samples that are selected to remain out of the learned model in order for the improve its prediction performance. This set of samples can be considered in closed-set and open-set scenarios. In the open-set scenario, discarding outliers can also reduce the OSR.
\end{itemize}


In this thesis the noise is separated in \textit{the Structured and Unstructured Noise} they are defined as follows:

\begin{itemize}
    \item \textit{Structured Noise} is the the negative samples with or without the side information available and the Outliers. These, samples are used in the evaluation phase of the experiments and also can be used for further algorithm evaluation in different openness test levels.
    \item \textit{Unstructured Noise} samples with no information related to them (positive, negative or both) and they only considered in the evaluation phase of the experiments or the production phase of a running open-set algorithm. That is when the algorithm is exposed to the real world scenario.
\end{itemize}

Therefore, the unstructured noise is equivalent to the unknown-unknown samples and the structured with the known-unknown samples. In addition, noise in both case is considered only in the testing-evaluation phase of the experiments and for the NNDR, also, at the validation phase.

In the next section the three open-set algorithms are described in detail, developed especially for this thesis and particularly for treating the WGI task. 


\section{One-Class SVM Ensemble}\label{chap:openset:sec:OCSVM_description}

One-class SVM is actually an $\nu$-SVM for the case we want to find the contour which is prescribing the positive samples of the training set given for a single class, while there are \textit{no negative samples}. $\nu$-SVM is providing an alternative \textit{trade-off control method of misclassification}, proposed from Scholkopf et al. \parencite{scholkopf1999estimating}. In $\nu$-SVM the eq.\ref{chap:openset:sec:eq:3} is minimized with the constraints of eq.\ref{chap:openset:sec:eq:4}, eq.\ref{chap:openset:sec:eq:5}.

Following the logic from the conventional SVM, thoroughly analyzed in \parencite{bishop2006}, the Lagrange multipliers for solving the optimization problem of eq.\ref{chap:openset:sec:eq:3} under eq.\ref{chap:openset:sec:eq:4}, eq.\ref{chap:openset:sec:eq:5} constraints are used. Equation \ref{chap:openset:sec:eq:12} is then derived, i.e. a Lagrangian function to be maximized as subject to the constraints eq.\ref{chap:openset:sec:eq:4}, eq.\ref{chap:openset:sec:eq:5}.

\begin{equation}\label{chap:openset:sec:eq:3}
	arg\min_{w,b}\left\{ \frac{1}{\nu\lambda}\sum_{n=1}^{N}(\xi_{n}-\rho)+\frac{1}{2}\|w\|^{2}\right\}
\end{equation}

\begin{equation}\label{chap:openset:sec:eq:4}
	0\leqslant a_{n}\leqslant1/N,\qquad n=1,...,N
\end{equation}

\begin{equation}\label{chap:openset:sec:eq:5}
	\nu\leqslant\sum_{n=1}^{N}a_{n}, \qquad \sum_{n=1}^{N}a_{n}t_{n}=0
\end{equation}

\begin{equation}\label{chap:openset:sec:eq:12}
	\widetilde{L}(a)=-\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{M}a_{n}a_{m}t_{n}t_{m}k(x_{n,}x_{m})
\end{equation}

\newpage


It should be noted that $\nu$ in $\nu$-SVM has the flowing properties:
\begin{itemize}
	\item $\nu$ is an upper bound on the fraction of \textit{Outliers}.
	\item $\nu$ is a lower bound on the fraction of \textit{Support Vectors}.
	\item $\nu$ values cannot exceed 1 (see eq.\ref{chap:openset:sec:eq:4}).
\end{itemize}

In practice different values of $\nu$ are defining different proportion of the training sample as outliers. For example in \parencite{scholkopf1999estimating} is showed that in their experiments when using $\nu=0.05$, 1.4\% of the training set has been classified as outliers while using $\nu=0.5$, 47.4\% is classified as outliers and 51.2\% is kept as SVs.

In the prediction phase in order for an OCSVM model to decide whether a document is belonging to the target genre-class (or not) a \textit{decision function} is used. The decision function indicates the distance of the document, positive or negative, to the hyperplane separating the classes. In the case of OCSVM we are usually only interested whether the decision function is positive or negative for deciding if an arbitrary document belonging or not to the target class.

In this thesis the Ensemble form of the OCSVM is used and first proposed in \parencite{pritsos2013open}. The \textit{OCSVM Ensemble} (OCSVME\footnote{The OCSVM ensemble was implemented in Python using the \textit{scikit-learn} package found in http://scikit-learn.org}) is as analytically described in algorithm \ref{chap:openset:sec:alg:OCSVM_Ensemble}. In the case of the OCSVME, we are interested in the positive and negative decision of each ensemble's classifier, and the decision scores.

\hfill

\begin{algorithm}[H]
\caption{The \textit{OCSVM} algorithm.}\label{chap:openset:sec:alg:OCSVM_Ensemble}
\KwData{ $G$ a genre palette and $W_{g}$ a set of known web-pages for each $g \in G$,
		 $w$ an unknown webpage of the $W_{a}$ arbitrary webpages set,
		 $F$ the feature set,
		 $\boldsymbol\nu$ the nu hyper-parameter of OCSVM,
         }
\KwResult{ $r \in \{G,\,\emptyset\}$ }
$score[:, :]$=0, the score 2D matrix where rows are for genre's class tags and columns for each webpage under evaluation
\For{each $g \in G$}{
  $Model(g) = ocsvmTrain(W_{g},F,\boldsymbol\nu)$, train a OCSVM model in vector space $F$ with hyper-paramenter $\boldsymbol\nu$ for genre $g$\;
}
\For{each $g \in G$}{
    \For{each $w \in W_{a}$}{
        $score[g, w] = ocsvmApply(Model(g),F,w)$, the distance of the unknown page $w$ from the hyperplane\;
    }
}
\eIf{$max(score[:, :])< 0$}{
    $r \in \emptyset$, i.e. none of the known genres or "I don't know";
}
{
        $r = argmax_{g \in G}(score[:, :])$, i.e. $w$ belongs to the genre of highest score\;
    }
\end{algorithm}

\hfill

In training phase of the ensemble one OCSVM is built for each known genre label. The hyper-parameter $\nu$ has the same value for all OCSVM models. In the prediction phase, the document is assigned to the class with the highest positive distance from the hyperplane (or the contour for OCSVM). If all OCSVMs return a negative distance (i.e. the web-page does not belong to this genre) the document remains unclassified, that is the final answer corresponds to "I Don't Know".


\section{Random Feature Subpacing Ensemble}\label{chap:openset:sec:RFSE_Description}

The RFSE algorithm is a variation of the method presented by Koppel et al. \parencite{koppel2011authorship} for the task of \textit{Author Identification}. In the original approach, there is only one training example for each author and a number of simple classifiers is learned based on random feature subspacing. Each classifier uses the \textit{Cosine (or other) distance} to estimate the most likely author. It is more likely for the true author to be selected by the majority of the classifiers since the used subset of features will still be able to reveal that high similarity. That is, the style of the author is captured by many different features so a subset of them will also contain enough stylistic information. Since WGI is also a style-based text categorization task, this idea should also work for it.

\hfill

\begin{algorithm}[H]
\caption{The \textit{RFSE} algorithm.}\label{chap:openset:sec:alg:RFS-Ensemble}
\KwData{ $G$ a genre palette and $W_{g}$ a set of known web-pages for each $g \in G$,
		 $w$ an arbitrary web-page of the $W_{a}$ arbitrary webpages set,
		 $F$ the feature set,
		 $fs$ a fraction of feature set size,
		 $I$ a number of iterations,
		 $\boldsymbol\sigma$ the decision threshold }
\KwResult{ $r \in \{G,\,\emptyset\}$ }
\For{each $g \in G$}{
  $centroid[g] = average(W_{g},F)$, average all known web-pages $W_{g}$ of genre $g$ to build a centroid vector\;
  $score[g]=0$\;
}
\Repeat{$I$ times}{
    $f = subset(F,fs)$, Randomly choose $fs$ features from the full feature set $F$\;
    \For{each $g$ in $G$}{
        \For{each $w$ in $W_{a}$}{
    	   $sim[g, w] = similarity(w, centroid(g), f)$, estimate similarity of unknown page $w$ with $centroid(g)$ in vector space $f$\;
        }
    }
   	$maxg = argmax_{g \in G}(sim[:, :])$, find the top match genre\;
   	$score(maxg) = score(maxg) + 1$, increase the score of top match genre\;
}

\eIf{$max(score(g))/I > \boldsymbol\sigma$}{
   $r = argmax_{g \in G}(score(g))$, assign the unknown page to genre with maximum top matches\;
}
{
      $r = \emptyset$, none of the known genres or "I don't know"\;
}
\end{algorithm}

\hfill

In this thesis the RFSE method is adopted, as introduced in \parencite{pritsos2013open} and shown in \textit{Algorithm \ref{chap:openset:sec:alg:RFS-Ensemble}}. There are multiple training examples for each available class. To maintain simplicity of classifiers, we have used a \textit{centroid vector} for each genre. In the training phase, a centroid vector is formed, for every class, by averaging all the Term-Frequency (TF) vectors of the training examples of web pages for each genre.

The class centroids are all formed for a given feature type. Then, an evaluation sample is compared against every centroid and this process is repeated $I$ times. Every time a different feature sub-set is used. Then, the scores are ranked from highest to lowest and we measure the number of times the sample is top-matched with every class. The sample is assigned to the genre with maximum number of matches given that this score exceed a predefined $\sigma$ threshold. In the opposite case, the sample remains unclassified, the RFSE responds "I Don't Know".

With respect to the similarity function, we examine cosine similarity (similar to \parencite{pritsos2013open}) and MinMax similarity (inspired by \parencite{koppel2014determining}). Moreover, measure that combines these two similarity functions, can be used. Then the most confident measure can be used in each iteration. More specifically, since Cosine and MinMax may have different mean and standard deviation for the set of all evaluation samples and all iterations per sample. Note that their values should first be normalized. Then, for each evaluation sample and each iteration we select the one with maximum normalized value. We call this similarity measure \textit{Combo}.

\section{Nearest Neighbors Distance Ratio}\label{chap:openset:sec:NNRD_Description}

The \tetxit{Nearest Neighbors Distance Ratio} (NNRD\footnote{The implementation of the NNRD algorithm can be found at \url{https://github.com/dpritsos/OpenNNDR}, where it is implemented in Python/Cython and can significantly accelerated using as much as possible CPUs due to its capability for concurrent calculations in C level speed. Since, NNRD is a rather slow classification method, we have seen in practice that there is up to 100 time acceleration from the capability to exploit a cloud service with 32 vCPUs (Xeon) compare to 4-core/8-threads i7 CPU.}) algorithm has been proposed as open-set algorithm by \parencite{mendesjunior2016}. In this thesis a specialized version has been implemented for the WGI task. In the original approach euclidean distance has been used because of the variation of data set on which the algorithm has been evaluated. In this thesis cosine distance is used, because in text classification is being confirmed to be the proper choice in hundreds of publications. Moreover, the cosine distance is comparable to the results of the \textit{Random Feature Sub-spacing Ensemble} algorithm found in \parencite{pritsos2018open} and also is tested in the open-set experiments of this thesis found in chapter \ref{chap:noise}.

The NNRD algorithm is an extension of the simple \textit{Nearest Neighbors} NN algorithm where additionally to the sets of training vectors (one set for each class) a threshold is selected by maximizing the \textit{Normalized Accuracy} (NA) as shown in equation\ref{chap:openset:sec:eq:NA}) on the \textit{Known} and the \textit{Marked as Unknown samples}.

\begin{equation} \label{chap:openset:sec:eq:NA}
    NA = \lambda A_{KS} + (1 - \lambda) A_{MUS}
\end{equation}

\noindent
where $A_{KS}$ is the \textit{Known Samples Accuracy} and $A_{MUS}$ is the \textit{Marked as Unknown Samples Accuracy}. The balance parameters $\lambda$ regulates the mistakes trade-off on the known and marked-unknown samples prediction.

The optimally selected threshold is the the \textit{Distance Ratio Threshold} (DRT) where NA is maximized. Equation \ref{eq:DR} is used for calculating the Distance Ratio (DR) of the two nearest class samples, say $s_{c_{a}}$ and $u_{c_{b}}$, to a random sample $r_{x}$ under the constrain $c_{a} \neq c_{b}$, where $c_{g}$ is the sample's class.

It is very important to note that the $c_{g}$ is trained in an open-set framework, therefore, the samples pairs selected for comparison might either be from the known of the marked as unknown samples. Thus $g \in {1,2,...,N}$ and $g = \emptyset$ when samples is marked as unknown.

\begin{equation} \label{eq:DR}
    DR = \frac{D(r_{x}, s_{c_{a}})}{D(r_{x}, s_{c_{b}})}
\end{equation}
\noindent
where $D(x,y)$ is the distance between the samples where in this study is the \textit{Cosine Distance}.

Therefore, the fitting function of the NN algorithm, described in pseudo-code \ref{chap:openset:alg:NNDR_fitting}, is the optimization procedure to find the DRT values for classes respective sets of training samples where NA is maximized.

\hfill

\begin{algorithm}[H]
\caption{\textit{Nearest Neighbor Distance Ratio} training data fitting function}\label{chap:openset:alg:NNDR_fitting}
\KwData{$G$ the set of genre class tags $\{1,2,...,N\}$,
        $p$ the hyper-parameter regulates the percentage of $G$ tags will be marked as unknown,
        $k$ the hyper-parameter regulates the percentage of known $G$ tags that will be keept for validation only,
        $T$ the \textit{Distance Ratio} thresholds set than will test for finding the one which is minimizing the \textit{Normalized Accuracy},
        $\lambda$ regulates the mistakes trade-off on the known and marked-unknown samples prediction (see eq.\ref{eq:DR}),
        $C[g]$ the matrix of class vector sets one for every genre class tag $g \in G$}
\KwResult{$DRT$ the \textit{Distance Ration Threshold} calculated by the NNRD algorithm's fitting function, $C[g]$}

$K^{G}_i, K^{G}_{validation}_i, U^{G}_{validation}_i, I^{G} = Split(G,p,k)$ splitting the $G$ tags in to known/unknown samples combinations using the $p$ and $k$ hyper-parameters. The amount of split combinations is calculated by the equations \ref{eq:splt_percent} and \ref{eq:splt}.\;

$V^{G} = U^{G}_{validation} \cup K^{G}_{validation}$ the validation set is the union of the $I$ splits of the known-validation and the marked-as-unknown sets, of the whole training set\;

\For{each $i \in I$}{
    $D^{cos}_{VK}[i] = COS_{D}(V^{G}_i, K^{G}_i)$ calculating all the Cosine Distances between the web-page of $K^{G}$ and $V^{G}$ sets for \textit{every $I$ split combination};
}

$Ci^{min}_{A} = argmin(D^{cos}_{VK})$ getting the indices of the closest classes from $V$\;
$Ci^{min}_{B} = argmin(D^{cos}_{VK})$ getting the indices of the \textit{second closest} classes from $V$\;

$R_{V} = D^{cos}_{VK}[Di^{min}_{A}] / D^{cos}_{VK}[Di^{min}_{B}]$ calculating the Distance Rations $R$ for all the vectors in $V$

$NA^{max} \gets 0$ initializing \textit{Maximized Normalized Accuracy} with $0$ value.
$DRT \gets 0$ initializing \textit{Distance Ratio Threshold} with $0$ value.

\For{each $drt \in T$}{

    \For{each $r, i \in \{R_{V}, count(R_{V})\}$}{

        \eIf{$r < drt$}{
            $vi = Ci^{min}_{A}[i]$ keep the respective index\;
            $Y[i] = G[vi]$ setting the genre's class tag as prediction for this random vector of set $V$\;
        }
        {
            $Y[i] = \emptyset$ setting as none of the known genres or "I don't know"\;
        }

    }

    $NA_{V} = NormalizedAccuracy(Y, R_{V})$ calculating the Normalized Accuracy as shown in equation \ref{eq:NA} for tested threshold $drt$\;

    \eIf{$NA_{V} > NA^{max}$}{
        $NA^{max} \gets NA_{V}$ keeping the maximum $NA$ until the outer for-loop finishes\;
        $DRT \gets drt$ keeping the \textit{Distance Ratio Threshold} maximizes the \textit{Normalized Accuracy}\;
    }

}

\end{algorithm}

\hfill

In the optimization procedure the training samples are split based on their class tags $c_{x}$. Then some class tags are \textit{marked as unknown} and some are left being known. Therefore, all the samples of the marked as unknown are used only in the validation subset while the known class tags samples are farther split into the classes sets (one for each class) and into the known validation set. Then, samples of the validation sets, both then known and then marked as unknown, are used seamlessly for calculating the set of Distance Rations (one for each class). Afterwards, a set of DRT values are tested given a range of values $R \in {t_{1}, t_{2}, t_{n}}$ beforehand where the $t_{x}$ is selected which is maximizing the NA of the validation set.

The splitting procedure the of the training set is regulated by a hyper-parameter $p$ which defines the percentage of the class tags set $g \in {1,2,...,N}$ where they will be marked as unknown. Then the total number of all possible splitting combination are calculated and these split-sets are used for finding the DRT. The combination are found using equations \ref{eq:splt_percent} and \ref{eq:splt}, where eq.\ref{eq:splt} is the \textit{Binomial Coefficient}.

\begin{equation} \label{eq:splt_percent}
    U_{num} = int(N * p)
\end{equation}

\noindent
where $N$ is the size of the class tags set ${1,2,...,N}$ and $p$ is the percentage regulation parameter for keeping the number of tags to be marked as unknown.

\begin{equation} \label{eq:splt}
    S_{num} = \frac{N!}{U_{num}!(N-U_{num})!}
\end{equation}

The NNDR is a open-set classification algorithm, therefore, every random sample will be classified to one of the classes the NNRD has been fitted or to the unknown when its DR is greater then DRT. While training as explained above the DRT values are tested incrementally until the optimal data fitting for the training function.

In prediction phase the DRT is passed to the NNDR prediction function together with the random samples and the training samples as shown in pseudo-code \ref{alg:NNDR_prediction}.

\hfill

\begin{algorithm}[H]
\caption{\textit{Nearest Neighbor Distance Ratio} prediction function}\label{alg:NNDR_prediction}
\KwData{ $W$ the vector set of the random web-page to be classified,
         $C[g]$ the matrix of class vector sets one for every genre class tag $g \in G$,
		 $DRT$ the \textit{Distance Ration Threshold} calculated by the NNRD algorithms fitting function}
\KwResult{ $Y \in \{G,\,\emptyset\}$,
           $R$ the Distance Ratio scores vector, one score for every input vector of the random set $W$}

\For{each $g \in G$}{
    $D^{cos}_{C_{g}X} = COS_{D}(C[g], X)$ calculating all the Cosine Distances between the random web-page vectors and the class vectors of class $g$\;
}

$Ci^{min}_{A} = argmin(D^{cos}_{C_{g}W})$ getting the indices of the closest classes from $W$\;
$Ci^{min}_{B} = argmin(D^{cos}_{C_{g}W})$ getting the indices of the \textit{second closest} classes from $W$\;

$R_{W} = D^{cos}_{C_{g}W}[Di^{min}_{A}] / D^{cos}_{C_{g}W}[Di^{min}_{B}]$ calculating the Distance Rations $R$ for all the vectors in $W$

\For{each $r, i \in \{R_{W}, count(R_{W})\}$}{

    \eIf{$r < DRT$}{
        $vi = Ci^{min}_{A}[i]$ keep the respective index\;
        $Y[i] = G[vi]$ setting the genre's class tag as prediction for this random vector of set $W$\;
    }
    {
        $Y[i] = \emptyset$ setting as none of the known genres or "I don't know"\;
    }

}

\end{algorithm}

\hfill


\section{Summary}\label{chap:openset:sec:NNRD_Description}

In this section the three implementation of open-set algorithms are presented which they are specialized for the WGI task, however, they can work also in different open-set domains. The definition of the open-set framework in the identification and the multi-class classification, forms.

In the context of the open-set framework and multi-class classification the \textit{Structured and Unstructured Noise} is defined for the first time. These definition are standing on the definition of the four special sample cased in the open-set framework. These definitions are expanding the \textit{Positive} and \textit{negative} categories of the samples found on the closed set scenarios with the \textit{Known} and \textit{Unknown} cases. 

The difference of the One-Class classification (and Novelty Detection) with the Open-set Classification is clarified and defined. Also, the \textit{Openness} of the problem is initially discussed which is indicating the level of difficulty of an open-set problem, where its score measurement method is discussed farther in chapter \ref{chap:eval_methods}.

Finally, the three major issues are captured using these three algorithms developed in this thesis; the luck of negative samples with the OCSVME, the noise tolerance with the RFSE, and the regularization of the open space risk with the NNDR. Although, the last is requiring the \textit{Distributional Features (an Neural Language Modeling)} input, discussed in chapter \ref{chap:word_embeddings}, for satisfying the its requirements of the WGI task.